# Probability Distributions - Normal distribution {#sec-distributions}

```{r}
#| include: false

library(tidyverse)
library(here)

library(stevemisc)
library(patchwork)

library(gganimate)


x <- seq(from=4-3*2, to= 4+3*2, length.out=400) # a vector of size 200 with numbers in [-4,4]
y <- dnorm(x, mean = 4, sd = 2) # y is a vector of the same size as x, with values from the PDF

```

## Sample Space and Random Events

In nature, people often encounter two types of **phenomena**:

-   One is the **deterministic phenomenon**, which is characterized by conditions under which the result is completely predictable, that is, the same result is observed each time the experiment is conducted. For example, water at 100°C under standard atmospheric pressure inevitably boils.

-   The other is the **random phenomenon**, which is characterized by conditions under which the result cannot be determined with certainty before it occurs, that is, one of several possible outcomes is observed each time the experiment is conducted. For example, when a coin is tossed, the outcome is either heads H or tails T, but unknown before the coin is tossed. Die rolling is also a random phenomenon, whose outcome is an integer from 1 to 6, unknown before the die is rolled. Likewise, for a bi-allelic gene A, the possible alleles are A and a, and the possible corresponding genotypes are AA, Aa, and aa.

The process of obtaining an observation or making a measurement for a random phenomenon/process is called a **random experiment** (briefly, an experiment), and is denoted by E.

The **sample space Ω** is defined as the set of **all** possible outcomes of the experiment. In the case of the roll of a die, the sample space can be written as the set of the six possible outcomes, Ω = {1, 2, 3, 4, 5, 6}.

Different experiments will have different sample spaces that can be written in an equivalent way (flipping a coin: Ω ={H, T}, flipping two coins: Ω ={HH, HT, TH, TT}, testing for possible genotypes of a bi-allelic gene A: Ω ={AA, Aa, aa}).

A **random event A**, or event A for short, is a sub-set of Ω, A ⊂ Ω, and it represents **a number** of possible outcomes for the experiment. In the case of the roll of a die, the event "even number" may be represented by A = {2, 4, 6}, and the event "odd number" as B = {1, 3, 5}. In the case of flipping two coins, an event could be that exactly one of the coins lands Heads, A = {HT, TH}.

::: callout-note
For each experiment, two events always exist: the **sample space** itself which comprises all possible outcomes and the **empty set** that contains no outcomes represented as **A = ∅** and called the impossible event.
:::

::: {.callout-caution collapse="true"}
## Basic types and operations of events using set theory

**Simple and Compound Events**

> If an event consists of a single outcome from the sample space, it is termed a **simple event**. The event of getting less than 2 on rolling a fair die, denoted as A = {1}, is an example of a simple event.
>
> If an event consists of more than a single outcome from the sample space, it is called a compound event. An example of a **compound event** in probability is rolling a fair die and getting an odd number, A = {1, 3, 5}.


**Union of Events** The union symbol (∪) is used to denote the OR event.

> For any two events A and B, "at least one of A and B occurs" is also an event. This event is called the union of A and B, and is denoted by **A∪ B**, which includes only A occurring, only B occurring, and A and B occurring simultaneously.
>
>In the experiment of rolling a single die, find the union of the events  A : “the number rolled is even” and  B : “the number rolled is greater than two.” 
Since the outcomes that are in either  A={2,4,6}  or  B={3,4,5,6}  (or both) are  2,3,4,5, and  6, that means  A ∪ B={2,3,4,5,6} .



**Intersection of Events** The intersection symbol (∩) is used to denote the AND event.

> For any two events A and B, “A and B occur simultaneously” is also an event. This event is called the intersection of A and B, and is denoted by A ∩ B.
>
> For example, A = {1, 2, 3, 4}, B = {2, 3, 5, 6} then A ∩ B = {2, 3}.




**Inverse Events**

> For any event A, “event A does not occur” is also an event. This event is called the inverse of event A or the complement of A, and is denoted by $\bar{A}$.


**Mutually Exclusive Events**

> For any two events A and B, if events A and B cannot occur simultaneously, that is, A ∩ B =∅, then A and B are called mutually exclusive events.



:::

## Probability

The concept of probability is used in day-to-day life which stands for the probability of occurring or non-occurring of events.

The first step towards determining the probability of an event is to establish a number of **basic rules** that capture the meaning of probability. The probability of an event is required to satisfy three **axioms** defined by **Kolmogorov**:

::: {.callout-warning icon="false"}
## **The Kolmogorov Axioms**

1.  The probability of an event A is a non-negative number, **P(A) ≥ 0**
2.  The probability of all possible outcomes, or sample space, is **P(Ω) = 1**
3.  If A and B are two mutually exclusive events, then **P(A ∪ B) = P(A) + P(B)** and **P(A ∩ B) = 0**. 

:::

::: {.callout-caution collapse="true"}
## Example - Mutually exclusive with dice

Suppose we throw a six-die what is the probability of rolling either 5 or 6?

The probability of rolling a 6 is 1/6 and the probability of a 5 is also 1/6. We cannot take a 5 and 6 at the same time (these events are mutually exclusive) so:

P(rolling a 5 or 6) = P(rolling a 5) + P(rolling a 6) = 1/6 + 1/6 = 1/3
:::

These axioms should be regarded as the basic "ground rules" of the theory of probability, but they provide no guidance on how event probabilities should be assigned. For this purpose, there are **two** major avenues available. One is based on the repetition of the experiments a large number of times under the same conditions, and goes under the name of the **frequentist approach**. The other is based on a more theoretical knowledge of the experiment, but without the experimental requirement of a large number of repetitions, and is referred to as the **Bayesian approach**.

 

### Definition of Probability

**A. Frequentist approach**

Consider performing an experiment a **large number** N of times, under the same experimental conditions. The occurrence of the event A is indicated as the number N(A). The probability of event A is given by:

$$ P(A) = \lim_{N\to\infty} \frac{N(A)}{N}$$ {#eq-probability}

that is, the probability is the relative frequency of occurrence of a given event from many repetitions of the same experiment.

The obvious **limitation** of this definition is the need to perform the experiment a **large number of times**. This requirement is not only time consuming but also requires that the experiment be repeatable in the first place, which may or may not be possible. The limitation of this method is evident by considering a **coin toss**: no matter the number of tosses, the occurrence of heads up **will never be exactly** 50%, which is what one would expect based on an empirical knowledge of the experiment at hand @fig-run.

::: callout-important
```{r}
#| echo: false
#| label: fig-run
#| out-width: "100%"
#| fig-align: "center"
#| fig-cap: Coin Flips Simulation showing long-term probability close to 0.5.

set.seed(123)
flips <- sample(c(0, 1), 500, replace = TRUE)
N <- seq(1, 500, 1)
flipsim <- data.frame(flips, N)
colnames(flipsim) <- c("Heads", "N")
flipsim[,"Cum_Heads"] <- cumsum(flipsim$Heads)

flipsim <- flipsim %>% 
  mutate(Pct_Heads = Cum_Heads/N)


flipsim %>% ggplot(aes(x = N, y = Pct_Heads)) + 
  geom_point(color = 'red', size = 4) +
  geom_hline(yintercept = 0.5) +
  ylim(0, 1) + 
  transition_time(N) +
  theme(plot.title = element_text(hjust = 0.5))
```
:::

Therefore, we may say that the probability of an event is the **relative frequency** of this set of outcomes over an indefinitely large number of experiments.

$$ P(A) \approx  \frac{number\ of\ times \ A\ occured}{total\ number\ of\  experiments}$$ {#eq-probability2}

::: callout-note
## Examples

**Prevalense of blood type**

Sampling many (say, 100,000) people in the Greece, finding that roughly 45,000 of them had blood type O. $$ P(O) \approx  \frac{number\ of\ people \ with\ blood\ type\ O}{total\ number\ of\  sample}= \frac{45,000}{100,000}=0.45$$ is the estimate for the probability for the event "having blood type O."

**Prevalence of a disease**

Suppose the **prevalence of diabetes** in the population is **1%**. The prevalence of a disease is the number of people in a population with the disease at a certain time divided by the number of people in the population. If a trial was then conducted by **randomly selecting one person** from the population and testing him or her for diabetes, the individual would be **expected to be diabetic with probability 0.01**. If this type of sampling of individuals from the population were repeated, then the proportion of diabetics in the total sample taken would be expected to be approximately 1%.
:::

**B. Bayesian approach**

Another method to assign probabilities is to use **knowledge** of the experiment, both theoretical and experimental, but without the need for extensive experimental data. The probability assigned to an event represents the **degree of belief** that the event will occur in a given try of the experiment, and it implies an element of subjectivity which will become more evident with Bayes' theorem.

::: callout-note
## Example - Coin toss experiment

In the coin toss experiment, the determination of the subjective probability for events "Heads up" or "Tails up" relies on the knowledge that the coin is **unbiased**, and therefore it must be true that P(T) = P(H). With this information, we can then simply use the Kolmogorov axioms to state that P(T) + P(H) = 1, and therefore obtain the intuitive result that P(T) = P(H) = 1/2.
:::

In this textbook, we'll focus on "Frequentist" approach of probability.

 

### Fundamental Properties of Probability

The following **properties** are useful to assign and manipulate event probabilities.

::: {.callout-warning icon="false"}
## Fundamental Properties of Probability

1.  The probability of the null event is zero, **P(∅) = 0**.

2.  The probability of the complementary event A satisfies the property:

$$P(A) = 1 − P(A)$$ {#eq-complementary}

3.  The probability of the union of two events satisfies the general property that (**Addition Rule of Probability**) :

$$P(A ∪ B) = P(A) + P(B) − P(A ∩ B)$$ {#eq-union}
:::

 

### The Conditional Probability

The conditional probability is indicated as **P(A\|B)** or A **given** B. The following relationship defines the conditional probability:

$$P(A ∩ B) = P(A|B) · P(B)$$ {#eq-conditional}

or

$$ P(A|B)=  \frac{P(A ∩ B)}{P(B)}$$ {#eq-conditional2}

::: {.callout-caution collapse="true"}
## Example - Conditional probability with dice

Calculate the probability of obtaining **8 as the sum of two rolls** of a die, **given that the first roll was a 3**.

The sample space of the experement consists of all ordered pairs of numbers from 1 to 6. That is, S = {(1, 1), (1, 2),... , (1, 6), (2, 1),... , (6, 6)}.

It is useful to define the following two events:

-   **A** = {The sum of two rolls is 8}. 

-   **B** = {The first roll shows 3, and the second any number}.

**Event A** is given by outcomes A={(2,6), (3,5), (4,4), (5,3), (6,2)} :

|              |     |       |     |     |     |
|--------------|-----|-------|-----|-----|-----|
| **1st roll** | 2   | **3** | 4   | 5   | 6   |
| **2nd roll** | 6   | **5** | 4   | 3   | 2   |
| **Sum**      | 8   | **8** | 8   | 8   | 8   |

and since each combination has a probability of 1/36, **P(A) = 5/36**.


**Event B** is given by outcomes B={(3,1), (3,2), (3,3), (3,4), (3,5), (3, 6)}. The probability of event B is **P(B) = 6/36 = 1/6**.

Also, the event A ∩ B occurs if the first roll is a 3 and the sum is 8, which can clearly occur only if a sequence of **(3,5)** takes place, thus with probability **P(A ∩ B) = 1/36**.

According to the definition of conditional probability @eq-conditional2, the probability of interest is:

$P(A|B) = \frac{P(A ∩ B)}{P(B)} = \frac{1/36}{1/6} = \frac{1}{6}$

Therefore, the occurrence of 3 in the first roll has  **increased** the probability of A from P(A) = 5/36 to P(A\|B) = 1/6.
:::

 

### Statistical Independence

The concept of statistical independence among events means that the occurrence of one event has **no influence** on the occurrence of other events. Consider, for example, rolling two dice, one after the other: the outcome of one die is independent of the other and the two tosses are said to be statistically independent.

On the other hand, consider rolling two dice, and being interested in the following pair of events: the first is the outcome of the roll of die 1 and the second is the sum the rolls of die 1 and die 2. It is clear that the outcome of the second event---e.g., the sum of both dice---depends on the first toss and the two events are not independent.

Two events A and B are said to be **statistically independent** if:

$$P(A ∩ B) = P(A) · P(B)$$ {#eq-independent}

@eq-independent, known as **Multiplication Rule of Probability**, follows directly from @eq-conditional. In fact, if A and B are statistically independent, then the conditional probability is P(A\|B) = P(A), i.e., the occurrence of B has no influence on the occurrence of A.


::: {.callout-caution collapse="true"}
## Example - Statistical independence with dice

Determine the probability of obtaining two 3s when rolling two dice. This event can be decomposed in two events:

-   **A** = {die 1 shows 3, and die 2 shows any number},

-   **B** = {die 2 shows 3, and die 1 shows any number}.

It is natural to assume that P(A) = 1/6, P(B) = 1/6, and state that the two events A and B are independent by nature, since each event involves a different die, which has no knowledge of the outcome of the other one; the same would be true also of the same die tossed two times. The event of interest is A ∩ B, and the definition of probability of two statistically independent events leads to $P(A ∩ B) = P(A) · P(B) = 1/36$.

This result can be confirmed by a direct count of all possible outcomes in the toss of two dice, and the fact that there is only one combination out of 36 that gives rise to two consecutive 3s.
:::

 

### Bayes' theorem

The Bayes' theorem can be written as:

$$P(A|B) = \frac{P(B|A)· P(A)}{P(B)}$$ {#eq-bayes}

where A and B are events and $P(B)\neq 0$.

The experiment B can be considered as the data collected in a given experiment. The event A is a model that is used to describe the data.

Accordingly, the probabilities involved in Bayes' theorem can be interpreted as follows:

(a) **P(B\|A)** is the probability, or **likelihood** L, of the data given the specified model. Notice how P(B\|A) means that the model A is given, or known.

(b) **P(A)** is the probability of the model A, without any knowledge of the data.This term is interpreted as a **prior probability**, or the degree of belief that the model is true before the measurements are made.

(c) **P(B)** is the probability of collecting the dataset B.

(d) Finally, **P(A\|B)** is the **posterior** **probability** of the model after the data have been collected.The posterior probability is the ultimate goal of the analysis since it describes the probability of the model based on the collection of data.

This interpretation of Bayes' theorem is the foundation of Bayesian statistics, and it can be summarized as:

**Posterior probability ∝ Likelihood × Prior probability**

Bayes' theorem provides a way to **update** the prior knowledge of model parameters given the measurements, leading to posterior estimates of parameters. One key feature of Bayesian statistics is that the calculation of probabilities is based on a **prior probability**, which may rely on a subjective interpretation of what is known about the experiment before any measurements are made. Therefore, great attention must be paid to the assignment of prior probabilities and the effect of priors on the final results of the analysis.

::: {.callout-caution collapse="true"}
## Example - Probability of developing lung cancer for smokers

Suppose that the probability of having lung cancer is P(C) = 0.001 and that the probability of being a smoker is P(SM) = 0.25

Further, suppose we know that if a person has lung cancer, the probability of being a smoker increases to P(SM\|C) = 0.4. We are, however, interested in the probability of developing lung cancer if a person is a smoker, P(C\|SM).

From @eq-bayes:

$$P(C|SM) = \frac{P(SM|C)· P(C)}{P(SM)} = \frac{0.4· 0.001}{0.25}= 0.0016$$ Therefore, the probability of lung cancer increases from 0.001 to 0.0016 for smokers. That is, the probability becomes 60% higher than the overall probability of lung cancer.
:::


 

## Random Variables

Formally, a random variable X assigns a numerical value to each possible outcome of a random phenomenon. For instance, we can define X based on
possible genotypes of a bi-allelic gene A as follows:

$$X={\begin{cases}0,&for\ genotype\ AA\\1,&for\ genotype\ Aa\\2,&for\ genotype\ aa\end{cases}}$$


In this case, the random variable assigns 0 to the outcome AA, 1 to the outcome Aa, and 2 to the outcome aa.

The set of values that a random variable can assume is called its range. For the above example, the range of X is {0, 1, 2}.

After we define a random variable, we can find the probabilities for its possible values based on the probabilities for its underlying random phenomenon. This way, instead of talking about the probabilities for different outcomes and events, we can talk about **the probability of different values for a random variable**.

Assume that the probabilities for different genotypes are P(AA) = 0.49, P(Aa) = 0.42, and P(aa) = 0.09. Then, instead of saying P(AA) = 0.49, i.e., the genotype is AA with probability 0.49, we can say that P(X = 0) = 0.49, i.e., X is equal to 0 with probability of 0.49. Likewise, P(X = 1) = 0.42 and P(X = 2) = 0.09. 


Note that the total probability for the random variable is still 1.
In what follows, we write P(X) to denote the probability of a random variable X in general without specifying any value or range of values.
**The probability rules we discussed earlier also apply to random variables**.
Specifically, concepts such as independence and conditional probability are defined similarly for random variables as they are defined for random events. For example, when two random variables do not affect each other’s probabilities, we say that they are independent.

A random variable is also expected to have a theoretical distribution, e.g., Normal, Poisson, etc., according to the nature of the variable itself and the method of measurement.



::: callout-note

Therefore, to fully understand a random variable, we need to know:

(1) **every possible value**, or the interval of values of the random variable.
(2) the **probabilities** corresponding to the values or value ranges (**probability distribution**).

:::


For the random variable X defined based on genotypes, the **probability distribution** can be simply specified as follows:

$$P(X=x)={\begin{cases}0.49,&for\ x=0\\0.42,&for\ x=1\\0.09,&for\ x=2\end{cases}}$$
Here, x denotes a specific value (i.e., 0, 1, or 2) of the random variable.
Probability distributions are specified differently for different types of random variables. In the following, we divide the random variables into two major groups: discrete and continuous. Then, we provide several examples for each group.


## Probability distribution for Discrete Outcomes







## Probability distributions for Continuous Outcomes

### **Normal Distribution**

We have mentioned the normal distribution several times in this textbook with the promise we would provide more detail later. In this section, we will explore the normal distribution, why it matters, and how we can tell if our distribution is normal or not.

#### Historical background and main properties

There are several important probability distributions in statistics. However, the normal distribution might be the most important. A normal distribution is the familiar "bell curve" and it's a way of formalizing a distribution where observations cluster around some central tendency. Observations farther from the central tendency occur less frequently. First, Galileo informally described a normal distribution in 1632 when discussing the random errors from observations of celestial phenomena. However, Galileo existed before the time of differential equations and derivatives. We owe its formalization to Carl Friedrich Gauss, which is why the normal distribution is often called a Gaussian distribution. A very familiar example is the height for adult people that approximates a normal distribution very well.

```{r}
#| echo: false
#| label: fig-dnormal
#| out-width: "100%"
#| fig-align: "center"
#| fig-cap: The Normal probability distribution (often called Gaussian or bell-shaped distribution).


x <- seq(-4, 4, length=100)
y <- dnorm(x)

plot(x,y, main="Normal Distribution", type = "l", lwd = 2,  xlab = "", ylab = "Probability Density", xaxt='n', frame.plot = FALSE)
axis(1, at = -3:3, lab=expression(-3*sigma, -2*sigma,-1*sigma, mu, 1*sigma, 2*sigma, 3*sigma))

```

 

The Normal distribution has the properties summarized as follows:

::: {.callout-note icon="false"}
## Properties of Normal Distribution

-   Bell shaped and symmetrical around the mean. Shape statistics, skewness and excess kurtosis are zero.

-   The peak of the curve lies above the mean

-   Any position along the horizontal axis (x-axis) can be expressed as a number of standard deviations from the mean

-   All three measures of central tendency, the mode (most frequently occurring value), the median (the middlemost value), and the mean (the statistical average), will be the same.

-   The total area under the curve equals to 1 (or 100%)
:::

 

### The mathimatical type

Gauss' normal distribution, technically a density function, is a distribution defined by two parameters, mean $\mu$ and variance $\sigma^2$. The mean, $\mu$, represents the population mean and is a "location parameter", which defines the central tendency. The variance, $\sigma^2$ is the "scale parameter", which defines the width of the distribution and how short the distribution is. It's formally given as @eq-gauss:

$$ f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma }}\right)^{2}} $$ {#eq-gauss}

Populations with small values of the standard deviation, $\sigma$, have a distribution concentrated close to the centre, $\mu$; those with large standard deviation, $\sigma$, have a distribution widely spread along the measurement axis @fig-compare_normal.

```{r}
#| echo: false
#| label: fig-compare_normal
#| fig-cap: Probability distribution functions of the Normal distributions with different means and standard deviations.
#| fig-subcap: 
#|   - "Effect of changing mean."
#|   - "Effect of changing standard deviation."
#| layout-ncol: 2

x <- seq(-6, 6, length=200)
y1 <- dnorm(x)
y2 <- dnorm(x, mean= 2)
y3 <- dnorm(x, sd= 2)

plot(x,y1, main="Normal Distribution", type = "l", lwd = 3,  xlab = "", ylab = "Probability Density", xaxt='n', frame.plot = FALSE)
axis(1, at = c(0, 2), lab = expression(mu[1], mu[2]))
lines(x,y2,col="deeppink", lwd = 3)
text(1.0, 0.4, expression(mu[1] < mu[2]), col="gray30")

plot(x,y1, main="Normal Distributions", type = "l", lwd = 3,  xlab = "", ylab = "Probability Density", xaxt='n', frame.plot = FALSE)
axis(1, at = -4:4, lab=expression(-4*sigma, -3*sigma, -2*sigma,-1*sigma, mu, 1*sigma, 2*sigma, 3*sigma, 4*sigma))
lines(x,y3,col="deeppink", lwd = 3)
text(1.5, 0.3, expression(sigma[1]))
text(2.9, 0.10, expression(sigma[2]), col="deeppink")
text(2.5, 0.20, expression(sigma[1] < sigma[2]), col="gray30")
```

The ensuing distribution will look like this in a simple case where $\mu$ is 0 and $\sigma^2$ is 1 (Standard Normal distribution).

```{r}
#| echo: false
#| label: fig-simple_normal
#| fig-height: 4.2
#| fig-width: 6.0
#| fig-align: "center"
#| fig-cap: A simple normal density function.

ggplot(data.frame(x = c(-4, 4)), aes(x)) + 
  theme_steve() + 
  post_bg() +
  stat_function(fun = dnorm, color="#522D80", size=1.5) +
  labs(title = "Standard Normal Distribution",
       subtitle = "The mu=0 parameter determines the central tendency and sigma-squared=1 parameter determines the width.",
       x = "", y="") +
  theme(plot.title.position = "plot",
        plot.title = element_text(size= 10),
        plot.subtitle = element_text(size= 8))
```

### Individual components of a normal distribution

We can break down individual components of a normal distribution and explain them until they seem more accessible.

**First**, the "kernel" is the part inside the exponent of the above equation (i.e. $\ {-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma }}\right)^{2}}$). Observe, for a simple case where $\mu$ = 0 and $\sigma^2$ = 1 that this part becomes $\ -{\frac {1}{2}}x^{2}$ that is a negative parabola (notice the square term). The minus sign just flips the basic parabola $\ {\frac {1}{2}}x^{2}$ downward.

```{r}
#| echo: false
#| label: fig-basic_parabola
#| fig-height: 4.0
#| fig-width: 8.0
#| fig-cap: (a) A basic parabola and (b) a negative parabola.

parab <- function(x) {x^2/2}
parab2 <- function(x) {-x^2/2}


p_parab <- ggplot(data.frame(x = c(-4, 4)), aes(x)) +
  stat_function(fun = parab, color="#522d80", size=1.5) +
  theme_steve() + 
  post_bg() +
  labs(title="A basic parabola",
       x = "", y="") +
theme(plot.title.position = "plot",
        plot.title = element_text(size= 10),
        plot.subtitle = element_text(size= 8))

p_parab2 <- ggplot(data.frame(x = c(-4, 4)), aes(x)) +
  stat_function(fun = parab2, color="#522d80", size=1.5) +
  theme_steve() + post_bg() +
  labs(title="A Negative Parabola",
       subtitle = "Notice the height is at 0 because the negative part \nflipped the parabola downward.",
       x = "", y="") +
theme(plot.title.position = "plot",
        plot.title = element_text(size= 10),
        plot.subtitle = element_text(size= 8))


p_parab + p_parab2
```

**Second**, exponentiating the negative parabola ($\  e^{-{\frac {1}{2}}x^{2}}$) makes it asymptote to 0.

```{r}
#| echo: false
#| label: fig-neg_parabola
#| fig-height: 4.2
#| fig-width: 6.0
#| fig-align: "center"
#| fig-cap: An exponentiated negative parabola.



expparab <- function(x) {exp(-x^2/2)}

p_expparab <- ggplot(data.frame(x = c(-4, 4)), aes(x)) +
  stat_function(fun = expparab, color="#522d80", size=1.5) +
  theme_steve() + 
  post_bg() +
  labs(title="An Exponentiated Negative Parabola",
       subtitle = "Exponentiating squeezes the parabola, adjusts the height, and makes \nthe tails asymptote to 0.",
       x = "", y="") +
theme(plot.title.position = "plot",
        plot.title = element_text(size= 10),
        plot.subtitle = element_text(size= 8))

p_expparab
```

Notice the tails in the above graph are asymptote to 0. "Asymptote" is a fancier way of saying the tails approximate 0 but never touch or surpass 0. One way of thinking about this as we build toward its inferential implications is that deviations farther from the central tendency are increasingly "unlikely".

**Third**, and with the above point in mind, it should be clear that $\ {\frac {1}{\sigma {\sqrt {2\pi }}}}$ will scale the height of the distribution. Observe that in our simple case where $\mu$ is 0 and $\sigma^2$ is 1, the height of the exponentiated parabola is at 1. That gets multiplied by $\ {\frac {1}{\sqrt {2\pi }}}$ to equal about 0.398.

**Fourth**, the normal distribution is perfectly symmetrical. The mean, $\mu$ determines the location of the distribution as well as its central tendency. All three measures of central tendency, the mode (most frequently occurring value), the median (the middlemost value), and the mean (the statistical average), will be the same. It also means a given observation of x will be as far from $\mu$ as -x. Additionally, the statistical moments of skewness and excess kurtosis are zero.

**Fifth**, we noted the normal distribution as a function and not a probability because the probability of any one value is effectively zero.

### Normal Density Plot with Shaded Regions

Importantly, much of the area (68%) of the distribution is between -sd and sd, the large majority (95%) between -2 sd and +2 sd, and almost all (99%) between -3 sd and + 3 sd. So, the probability that x is between 1 on either side of the $\mu$ of 0 is effectively 0.68. The ease of this interpretation is why researchers like to standardize their variables so that the mean is 0 and the standard deviation (i.e. the scale parameter) is 1.

```{r}
#| echo: false
#| label: fig-auc
#| fig-height: 7.2
#| fig-width: 12.0
#| fig-align: "center"
#| fig-cap: The area underneath a normal distribution


normal_dist("#522d80","#F66733") + 
  theme_steve() + post_bg() +
    labs(title = "The Area Underneath a Normal Distribution",
       subtitle = "The tails extend to infinity and are asymptote to zero, but the full domain sums to 1. The 95% of all possible values are within about 1.96 standard units from the mean.",
       y = "Density",
       x = "")
```

The normal distribution appears as a foundation assumption for a lot of quantitative approaches to frequentist statistics.

In summary, the normal density function is technically unbounded. It has just the two parameters that define its location and scale and the tails are asymptote to 0 no matter what the values of $\mu$ and $\sigma^2$ are. This makes the distribution continuous since x can range over the entire line from $\ -\infty$ to $\ +\infty$. Thus, the function does not reveal the probability of x (the probability of any one value is effectively 0). However, the area under the curve is the full domain of the probability space and sums to 1. The probability of selecting a number between two points on the x-axis equals the area under the curve between those two points.

```{r}
#| echo: false
#| label: fig-standard_normal
#| fig-height: 6.0
#| fig-width: 8.0
#| fig-align: "center"
#| fig-cap: Standard normal distribution with a shaded region

x <- seq(from=-3, to= 3, length.out=200) # a vector of size 200 with numbers in [-4,4]
y <- dnorm(x) # y is a vector of the same size as x, with values from the PDF

# The polygon follows the density curve where 1 <= x <= 2
region.x <- x[1 <= x & x <= 2] # subset from x satisfying the condition
region.y <- y[1 <= x & x <= 2] # subset from y satisfying the condition
# We add initial and final segments, which drop down to the Y axis
region.x <- c(region.x[1], region.x, tail(region.x,1))
region.y <- c(0,region.y,0)


plot(x, y, main="Standard Normal Distribution with a Shaded Region",
type='l', ylab="Density", xlab="x",lwd=3,col="#522d80")
abline(h=0) # adds the x-axis to the plot
polygon(region.x, region.y, density=-1, col="#F66733")

```

To find the area between x = 1 and x = 2, we must integrate the @eq-gauss as following:

$$ E(x)=\int_{1}^{2}f(x)dx $$ {#eq-integral}

 

#### Properties of an approximately bell-shaped histogram

In an approximately **bell-shaped (normal)** distribution:

-   the mean, the median and the mode have very close values

-   the histogram is symmetric about the mean

-   "nearly all" values (99.7%) are within -3 and +3 standard deviations of the mean

-   the measure of skewness takes values close to zero (symmetric distribution) (@fig-skew2 b). Particularly, values between −1 and +1 indicate an approximate bell-shaped curve.

-   the measure of excess kurtosis is close to 0 (mesokurtic) (@fig-kurtosis b). A kurtosis value between −1 and +1 indicates normality.

#### **t-distribution**

#### **Chi-squared distribution**

#### **F-distribution**

::: callout-tip
**Statistical moments (or shape statistics) and normality**

There are two shape statistics that can indicate deviation from normality: **skew** and **kurtosis**.

**Skewness**

Skewness is usually described as a measure of a dataset's symmetry -- or lack of symmetry.

Skewness values that are **negative** indicate a tail to the **left** (@fig-skew2 a), **zero** value indicate a **symmetric** distribution (@fig-skew2 b), while values that are **positive** indicate a tail to the **right** (@fig-skew2 c).

Skewness values between −1 and +1 indicate an approximate bell-shaped curve. Values from −1 to −3 or from +1 to +3 indicate that the distribution is tending away from a bell shape with \>1 indicating moderate skewness and \>2 indicating severe skewness. Any values above +3 or below−3 are a good indication that the variable is not normally distributed.

```{r}
#| echo: false
#| label: fig-skew2
#| out-width: "105%"
#| fig-align: "center"
#| fig-cap: A distribution can be (a) skewed to the left, (b) symmetric, or (c) skewed to the right.


knitr::include_graphics(here("images", "skew2.png"))
```

 

**Kurtosis**

The other way that distributions can deviate from normality is **kurtosis**. The kurtosis parameter is a measure of the combined weight of the tails relative to the rest of the distribution. Kurtosis is associated indirect with the peak of the distribution (if the peak of the distribution is too high or too low).

Distributions with **negative** excess kurtosis are called ***platykurtic*** (@fig-kurtosis a). If the measure of excess kurtosis is **0** the distribution is **mesokurtic** (@fig-kurtosis b). Finally, distributions with **positive** excess kurtosis are called ***leptokurtic*** (@fig-kurtosis c).

A kurtosis value between −1 and +1 indicates normality and a value between −1 and −3 or between +1 and +3 indicates a tendency away from normality. Values below −3 or above +3 strongly indicate non-normality.

```{r}
#| echo: false
#| label: fig-kurtosis
#| out-width: "105%"
#| fig-align: "center"
#| fig-cap: A distribution can be (a) platykurtic, (b) mesokurtic, or (c) leptokurtic.


knitr::include_graphics(here("images", "kurtosis.png"))
```
:::
