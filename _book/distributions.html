<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="generator" content="quarto-1.0.37">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<title>Introduction to Medical Statistics with Jamovi - 3&nbsp; Probability Distributions - Normal distribution</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>

<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./estimation.html" rel="next">
<link href="./descriptive.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light"><script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
</head>
<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top"><nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }"><div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability Distributions - Normal distribution</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav></header><!-- content --><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto"><div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Introduction to Medical Statistics with Jamovi</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/bougioukas/MedStatsJamovi5" title="Source Code" class="sidebar-tool px-1"><i class="bi bi-github"></i></a>
    <a href="" title="Share" id="sidebar-tool-dropdown-0" class="sidebar-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false"><i class="bi bi-share"></i></a>
    <ul class="dropdown-menu" aria-labelledby="sidebar-tool-dropdown-0">
<li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://twitter.com/intent/tweet?url=%7Curl%7C">
            <i class="bi bi-bi-twitter pe-1"></i>
          Twitter
          </a>
        </li>
        <li>
          <a class="dropdown-item sidebar-tools-main-item" href="https://www.facebook.com/sharer/sharer.php?u=%7Curl%7C">
            <i class="bi bi-bi-facebook pe-1"></i>
          Facebook
          </a>
        </li>
    </ul>
</div>
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">Preface</a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Medical Statistics</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./descriptive.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Descriptive statistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./distributions.html" class="sidebar-item-text sidebar-link active"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability Distributions - Normal distribution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./estimation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Estimation and Confidence Interval</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Foundations for statistical inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./two_samples.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Inference for numerical data: 2 samples</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./more_samples.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Inference for numerical data: &gt;2 samples</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./categorical.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Inference for categorical data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./correlation.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Correlation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Simple linear regression</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Jamovi LAB</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">
<li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lab1.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">LAB I: Introduction to Jamovi</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lab2.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">LAB II: Descriptive Statistics</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lab3.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">LAB III: Probability Distributions-Normal Distribution</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lab4.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">LAB IV: Estimation and Confidence Interval</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lab5.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">LAB V: Foundations for Statistical Inference</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lab6.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">LAB VI: Inference for numerical data (2 samples)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lab7.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">LAB VII: Inference for numerical data (&gt;2 samples)</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lab8.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">LAB VIII: Inference for categorical data</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lab9.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">LAB IX: Correlation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lab10.html" class="sidebar-item-text sidebar-link"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">LAB X: Simple linear regression</span></a>
  </div>
</li>
      </ul>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">References</a>
  </div>
</li>
    </ul>
</div>
</nav><!-- margin-sidebar --><div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc"><h2 id="toc-title">Table of contents</h2>
   
  <ul>
<li><a href="#sample-space-and-random-events" id="toc-sample-space-and-random-events" class="nav-link active" data-scroll-target="#sample-space-and-random-events"> <span class="header-section-number">3.1</span> Sample Space and Random Events</a></li>
  <li>
<a href="#probability" id="toc-probability" class="nav-link" data-scroll-target="#probability"> <span class="header-section-number">3.2</span> Probability</a>
  <ul class="collapse">
<li><a href="#definition-of-probability" id="toc-definition-of-probability" class="nav-link" data-scroll-target="#definition-of-probability">Definition of Probability</a></li>
  <li><a href="#fundamental-properties-of-probability" id="toc-fundamental-properties-of-probability" class="nav-link" data-scroll-target="#fundamental-properties-of-probability">Fundamental Properties of Probability</a></li>
  <li><a href="#the-conditional-probability" id="toc-the-conditional-probability" class="nav-link" data-scroll-target="#the-conditional-probability">The Conditional Probability</a></li>
  <li><a href="#statistical-independence" id="toc-statistical-independence" class="nav-link" data-scroll-target="#statistical-independence">Statistical Independence</a></li>
  <li><a href="#bayes-theorem" id="toc-bayes-theorem" class="nav-link" data-scroll-target="#bayes-theorem">Bayes’ theorem</a></li>
  </ul>
</li>
  <li><a href="#random-variables" id="toc-random-variables" class="nav-link" data-scroll-target="#random-variables"> <span class="header-section-number">3.3</span> Random Variables</a></li>
  <li>
<a href="#probability-distributions-for-discrete-outcomes" id="toc-probability-distributions-for-discrete-outcomes" class="nav-link" data-scroll-target="#probability-distributions-for-discrete-outcomes"> <span class="header-section-number">3.4</span> Probability distributions for Discrete Outcomes</a>
  <ul class="collapse">
<li><a href="#bernoulli-distribution" id="toc-bernoulli-distribution" class="nav-link" data-scroll-target="#bernoulli-distribution"><strong>Bernoulli distribution</strong></a></li>
  <li><a href="#binomial-distribution" id="toc-binomial-distribution" class="nav-link" data-scroll-target="#binomial-distribution"><strong>Binomial distribution</strong></a></li>
  <li><a href="#poisson-distribution" id="toc-poisson-distribution" class="nav-link" data-scroll-target="#poisson-distribution"><strong>Poisson distribution</strong></a></li>
  </ul>
</li>
  <li>
<a href="#probability-distributions-for-continuous-outcomes" id="toc-probability-distributions-for-continuous-outcomes" class="nav-link" data-scroll-target="#probability-distributions-for-continuous-outcomes"> <span class="header-section-number">3.5</span> Probability distributions for Continuous Outcomes</a>
  <ul class="collapse">
<li><a href="#normal-distribution" id="toc-normal-distribution" class="nav-link" data-scroll-target="#normal-distribution"><strong>Normal Distribution</strong></a></li>
  <li><a href="#standard-normal-distribution" id="toc-standard-normal-distribution" class="nav-link" data-scroll-target="#standard-normal-distribution"><strong>Standard Normal distribution</strong></a></li>
  </ul>
</li>
  </ul></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content"><header id="title-block-header" class="quarto-title-block default"><div class="quarto-title">
<h1 class="title"><span id="sec-distributions" class="quarto-section-identifier d-none d-lg-block"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Probability Distributions - Normal distribution</span></span></h1>
</div>



<div class="quarto-title-meta">

    
    
  </div>
  

</header><section id="sample-space-and-random-events" class="level2" data-number="3.1"><h2 data-number="3.1" class="anchored" data-anchor-id="sample-space-and-random-events">
<span class="header-section-number">3.1</span> Sample Space and Random Events</h2>
<p>In nature, people often encounter two types of <strong>phenomena</strong>:</p>
<ul>
<li><p>One is the <strong>deterministic phenomenon</strong>, which is characterized by conditions under which the result is completely predictable, that is, the same result is observed each time the experiment is conducted. For example, water at 100°C under standard atmospheric pressure inevitably boils.</p></li>
<li><p>The other is the <strong>random phenomenon</strong>, which is characterized by conditions under which the result cannot be determined with certainty before it occurs, that is, one of several possible outcomes is observed each time the experiment is conducted. For example, when a coin is tossed, the outcome is either heads H or tails T, but unknown before the coin is tossed. Die rolling is also a random phenomenon, whose outcome is an integer from 1 to 6, unknown before the die is rolled. Likewise, for a bi-allelic gene A, the possible alleles are A and a, and the possible corresponding genotypes are AA, Aa, and aa.</p></li>
</ul>
<p>The process of obtaining an observation or making a measurement for a random phenomenon/process is called a <strong>random experiment</strong> (briefly, an experiment), and is denoted by E.</p>
<p>The <strong>sample space Ω</strong> is defined as the set of <strong>all</strong> possible outcomes of the experiment. In the case of the roll of a die, the sample space can be written as the set of the six possible outcomes, Ω = {1, 2, 3, 4, 5, 6}.</p>
<p>Different experiments will have different sample spaces that can be written in an equivalent way (flipping a coin: Ω ={H, T}, flipping two coins: Ω ={HH, HT, TH, TT}, testing for possible genotypes of a bi-allelic gene A: Ω ={AA, Aa, aa}).</p>
<p>A <strong>random event A</strong>, or event A for short, is a sub-set of Ω, A ⊂ Ω, and it represents <strong>a number</strong> of possible outcomes for the experiment. In the case of the roll of a die, the event “even number” may be represented by A = {2, 4, 6}, and the event “odd number” as B = {1, 3, 5}. In the case of flipping two coins, an event could be that exactly one of the coins lands Heads, A = {HT, TH}.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Two events always exist for an experiment
</div>
</div>
<div class="callout-body-container callout-body">
<p>For each experiment, two events always exist: the <strong>sample space</strong> itself which comprises all possible outcomes and the <strong>empty set</strong> that contains no outcomes represented as <strong>A = ∅</strong> and called the impossible event.</p>
</div>
</div>
<div class="callout-caution callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Basic types and operations of events using set theory
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Simple and Compound Events</strong></p>
<blockquote class="blockquote">
<p>If an event consists of a single outcome from the sample space, it is termed a <strong>simple event</strong>. The event of getting less than 2 on rolling a fair die, denoted as A = {1}, is an example of a simple event.</p>
<p>If an event consists of more than a single outcome from the sample space, it is called a compound event. An example of a <strong>compound event</strong> in probability is rolling a fair die and getting an odd number, A = {1, 3, 5}.</p>
</blockquote>
<p><strong>Union of Events</strong> The union symbol (∪) is used to denote the OR event.</p>
<blockquote class="blockquote">
<p>For any two events A and B, “at least one of A and B occurs” is also an event. This event is called the union of A and B, and is denoted by <strong>A∪ B</strong>, which includes only A occurring, only B occurring, and A and B occurring simultaneously.</p>
<p>In the experiment of rolling a single die, find the union of the events A : “the number rolled is even” and B : “the number rolled is greater than two.” Since the outcomes that are in either A={2,4,6} or B={3,4,5,6} (or both) are 2,3,4,5, and 6, that means A ∪ B={2,3,4,5,6} .</p>
</blockquote>
<p><strong>Intersection of Events</strong> The intersection symbol (∩) is used to denote the AND event.</p>
<blockquote class="blockquote">
<p>For any two events A and B, “A and B occur simultaneously” is also an event. This event is called the intersection of A and B, and is denoted by A ∩ B.</p>
<p>For example, A = {1, 2, 3, 4}, B = {2, 3, 5, 6} then A ∩ B = {2, 3}.</p>
</blockquote>
<p><strong>Inverse Events</strong></p>
<blockquote class="blockquote">
<p>For any event A, “event A does not occur” is also an event. This event is called the inverse of event A or the complement of A, and is denoted by <span class="math inline">\(\bar{A}\)</span>.</p>
</blockquote>
<p><strong>Mutually Exclusive Events</strong></p>
<blockquote class="blockquote">
<p>For any two events A and B, if events A and B cannot occur simultaneously, that is, A ∩ B =∅, then A and B are called mutually exclusive events.</p>
</blockquote>
</div>
</div>
</div>
</section><section id="probability" class="level2" data-number="3.2"><h2 data-number="3.2" class="anchored" data-anchor-id="probability">
<span class="header-section-number">3.2</span> Probability</h2>
<p>The concept of probability is used in day-to-day life which stands for the probability of occurring or non-occurring of events.</p>
<p>The first step towards determining the probability of an event is to establish a number of <strong>basic rules</strong> that capture the meaning of probability. The probability of an event is required to satisfy three <strong>axioms</strong> defined by <strong>Kolmogorov</strong>:</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
<strong>The Kolmogorov Axioms</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li>The probability of an event A is a non-negative number, <strong>P(A) ≥ 0</strong>
</li>
<li>The probability of all possible outcomes, or sample space, is <strong>P(Ω) = 1</strong>
</li>
<li>If A and B are two mutually exclusive events, then <strong>P(A ∪ B) = P(A) + P(B)</strong> and <strong>P(A ∩ B) = 0</strong>.</li>
</ol>
</div>
</div>
<div class="callout-caution callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example - Mutually exclusive with dice
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Suppose we throw a six-die what is the probability of rolling either 5 or 6?</p>
<p>The probability of rolling a 6 is 1/6 and the probability of a 5 is also 1/6. We cannot take a 5 and 6 at the same time (these events are mutually exclusive) so:</p>
<p>P(rolling a 5 or 6) = P(rolling a 5) + P(rolling a 6) = 1/6 + 1/6 = 1/3</p>
</div>
</div>
</div>
<p>These axioms should be regarded as the basic “ground rules” of the theory of probability, but they provide no guidance on how event probabilities should be assigned. For this purpose, there are <strong>two</strong> major avenues available. One is based on the repetition of the experiments a large number of times under the same conditions, and goes under the name of the <strong>frequentist approach</strong>. The other is based on a more theoretical knowledge of the experiment, but without the experimental requirement of a large number of repetitions, and is referred to as the <strong>Bayesian approach</strong>.</p>
<p>&nbsp;</p>
<section id="definition-of-probability" class="level3"><h3 class="anchored" data-anchor-id="definition-of-probability">Definition of Probability</h3>
<p><strong>A. Frequentist approach</strong></p>
<p>Consider performing an experiment a <strong>large number</strong> N of times, under the same experimental conditions. The occurrence of the event A is indicated as the number N(A). The probability of event A is given by:</p>
<p><span id="eq-probability"><span class="math display">\[ P(A) = \lim_{N\to\infty} \frac{N(A)}{N} \tag{3.1}\]</span></span></p>
<p>that is, the probability is the relative frequency of occurrence of a given event from many repetitions of the same experiment.</p>
<p>The obvious <strong>limitation</strong> of this definition is the need to perform the experiment a <strong>large number of times</strong>. This requirement is not only time consuming but also requires that the experiment be repeatable in the first place, which may or may not be possible. The limitation of this method is evident by considering a <strong>coin toss</strong>: no matter the number of tosses, the occurrence of heads up <strong>will never be exactly</strong> 50%, which is what one would expect based on an empirical knowledge of the experiment at hand <a href="#fig-run">Figure&nbsp;<span>3.1</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-run" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-run-1.gif" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 3.1: Coin Flips Simulation showing long-term probability close to 0.5.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Therefore, we may say that the probability of an event is the <strong>relative frequency</strong> of this set of outcomes over an indefinitely large number of experiments.</p>
<p><span id="eq-probability2"><span class="math display">\[ P(A) \approx  \frac{number\ of\ times \ A\ occured}{total\ number\ of\  experiments} \tag{3.2}\]</span></span></p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Examples: Probability based on on Frequentist approach
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Prevalense of blood type</strong></p>
<p>Sampling many (say, 100,000) people in the Greece, finding that roughly 45,000 of them had blood type O. <span class="math display">\[ P(O) \approx  \frac{number\ of\ people \ with\ blood\ type\ O}{total\ number\ of\  sample}= \frac{45,000}{100,000}=0.45\]</span> is the estimate for the probability for the event “having blood type O.”</p>
<p><strong>Prevalence of a disease</strong></p>
<p>Suppose the <strong>prevalence of diabetes</strong> in the population is <strong>1%</strong>. The prevalence of a disease is the number of people in a population with the disease at a certain time divided by the number of people in the population. If a trial was then conducted by <strong>randomly selecting one person</strong> from the population and testing him or her for diabetes, the individual would be <strong>expected to be diabetic with probability 0.01</strong>. If this type of sampling of individuals from the population were repeated, then the proportion of diabetics in the total sample taken would be expected to be approximately 1%.</p>
</div>
</div>
<p><strong>B. Bayesian approach</strong></p>
<p>Another method to assign probabilities is to use <strong>knowledge</strong> of the experiment, both theoretical and experimental, but without the need for extensive experimental data. The probability assigned to an event represents the <strong>degree of belief</strong> that the event will occur in a given try of the experiment, and it implies an element of subjectivity which will become more evident with Bayes’ theorem.</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example - Coin toss experiment
</div>
</div>
<div class="callout-body-container callout-body">
<p>In the coin toss experiment, the determination of the subjective probability for events “Heads up” or “Tails up” relies on the knowledge that the coin is <strong>unbiased</strong>, and therefore it must be true that P(T) = P(H). With this information, we can then simply use the Kolmogorov axioms to state that P(T) + P(H) = 1, and therefore obtain the intuitive result that P(T) = P(H) = 1/2.</p>
</div>
</div>
<p>In this textbook, we’ll focus on “Frequentist” approach of probability.</p>
<p>&nbsp;</p>
</section><section id="fundamental-properties-of-probability" class="level3"><h3 class="anchored" data-anchor-id="fundamental-properties-of-probability">Fundamental Properties of Probability</h3>
<p>The following <strong>properties</strong> are useful to assign and manipulate event probabilities.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Fundamental Properties of Probability
</div>
</div>
<div class="callout-body-container callout-body">
<ol type="1">
<li><p>The probability of the null event is zero, <strong>P(∅) = 0</strong>.</p></li>
<li><p>The probability of the complementary event A satisfies the property:</p></li>
</ol>
<p><span id="eq-complementary"><span class="math display">\[P(A) = 1 − P(A) \tag{3.3}\]</span></span></p>
<ol start="3" type="1">
<li>The probability of the union of two events satisfies the general property that (<strong>Addition Rule of Probability</strong>) :</li>
</ol>
<p><span id="eq-union"><span class="math display">\[P(A ∪ B) = P(A) + P(B) − P(A ∩ B) \tag{3.4}\]</span></span></p>
</div>
</div>
<p>&nbsp;</p>
</section><section id="the-conditional-probability" class="level3"><h3 class="anchored" data-anchor-id="the-conditional-probability">The Conditional Probability</h3>
<p>The conditional probability is indicated as <strong>P(A|B)</strong> or A <strong>given</strong> B. The following relationship defines the conditional probability:</p>
<p><span id="eq-conditional"><span class="math display">\[P(A ∩ B) = P(A|B) · P(B) \tag{3.5}\]</span></span></p>
<p>or</p>
<p><span id="eq-conditional2"><span class="math display">\[ P(A|B)=  \frac{P(A ∩ B)}{P(B)} \tag{3.6}\]</span></span></p>
<div class="callout-caution callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example - Conditional probability with dice
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Calculate the probability of obtaining <strong>8 as the sum of two rolls</strong> of a die, <strong>given that the first roll was a 3</strong>.</p>
<p>The sample space of the experement consists of all ordered pairs of numbers from 1 to 6. That is, S = {(1, 1), (1, 2),… , (1, 6), (2, 1),… , (6, 6)}.</p>
<p>It is useful to define the following two events:</p>
<ul>
<li><p><strong>A</strong> = {The sum of two rolls is 8}.</p></li>
<li><p><strong>B</strong> = {The first roll shows 3, and the second any number}.</p></li>
</ul>
<p><strong>Event A</strong> is given by outcomes A={(2,6), (3,5), (4,4), (5,3), (6,2)} :</p>
<table class="table"><tbody>
<tr class="odd">
<td><strong>1st roll</strong></td>
<td>2</td>
<td><strong>3</strong></td>
<td>4</td>
<td>5</td>
<td>6</td>
</tr>
<tr class="even">
<td><strong>2nd roll</strong></td>
<td>6</td>
<td><strong>5</strong></td>
<td>4</td>
<td>3</td>
<td>2</td>
</tr>
<tr class="odd">
<td><strong>Sum</strong></td>
<td>8</td>
<td><strong>8</strong></td>
<td>8</td>
<td>8</td>
<td>8</td>
</tr>
</tbody></table>
<p>and since each combination has a probability of 1/36, <strong>P(A) = 5/36</strong>.</p>
<p><strong>Event B</strong> is given by outcomes B={(3,1), (3,2), (3,3), (3,4), (3,5), (3, 6)}. The probability of event B is <strong>P(B) = 6/36 = 1/6</strong>.</p>
<p>Also, the event A ∩ B occurs if the first roll is a 3 and the sum is 8, which can clearly occur only if a sequence of <strong>(3,5)</strong> takes place, thus with probability <strong>P(A ∩ B) = 1/36</strong>.</p>
<p>According to the definition of conditional probability <a href="#eq-conditional2">Equation&nbsp;<span>3.6</span></a>, the probability of interest is:</p>
<p><span class="math inline">\(P(A|B) = \frac{P(A ∩ B)}{P(B)} = \frac{1/36}{1/6} = \frac{1}{6}\)</span></p>
<p>Therefore, the occurrence of 3 in the first roll has <strong>increased</strong> the probability of A from P(A) = 5/36 to P(A|B) = 1/6.</p>
</div>
</div>
</div>
<p>&nbsp;</p>
</section><section id="statistical-independence" class="level3"><h3 class="anchored" data-anchor-id="statistical-independence">Statistical Independence</h3>
<p>The concept of statistical independence among events means that the occurrence of one event has <strong>no influence</strong> on the occurrence of other events. Consider, for example, rolling two dice, one after the other: the outcome of one die is independent of the other and the two tosses are said to be statistically independent.</p>
<p>On the other hand, consider rolling two dice, and being interested in the following pair of events: the first is the outcome of the roll of die 1 and the second is the sum the rolls of die 1 and die 2. It is clear that the outcome of the second event—e.g., the sum of both dice—depends on the first toss and the two events are not independent.</p>
<p>Two events A and B are said to be <strong>statistically independent</strong> if:</p>
<p><span id="eq-independent"><span class="math display">\[P(A ∩ B) = P(A) · P(B) \tag{3.7}\]</span></span></p>
<p><a href="#eq-independent">Equation&nbsp;<span>3.7</span></a>, known as <strong>Multiplication Rule of Probability</strong>, follows directly from <a href="#eq-conditional">Equation&nbsp;<span>3.5</span></a>. In fact, if A and B are statistically independent, then the conditional probability is P(A|B) = P(A), i.e., the occurrence of B has no influence on the occurrence of A.</p>
<div class="callout-caution callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example - Statistical independence with dice
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Determine the probability of obtaining two 3s when rolling two dice. This event can be decomposed in two events:</p>
<ul>
<li><p><strong>A</strong> = {die 1 shows 3, and die 2 shows any number},</p></li>
<li><p><strong>B</strong> = {die 2 shows 3, and die 1 shows any number}.</p></li>
</ul>
<p>It is natural to assume that P(A) = 1/6, P(B) = 1/6, and state that the two events A and B are independent by nature, since each event involves a different die, which has no knowledge of the outcome of the other one; the same would be true also of the same die tossed two times. The event of interest is A ∩ B, and the definition of probability of two statistically independent events leads to <span class="math inline">\(P(A ∩ B) = P(A) · P(B) = 1/36\)</span>.</p>
<p>This result can be confirmed by a direct count of all possible outcomes in the toss of two dice, and the fact that there is only one combination out of 36 that gives rise to two consecutive 3s.</p>
</div>
</div>
</div>
<p>&nbsp;</p>
</section><section id="bayes-theorem" class="level3"><h3 class="anchored" data-anchor-id="bayes-theorem">Bayes’ theorem</h3>
<p>The Bayes’ theorem can be written as:</p>
<p><span id="eq-bayes"><span class="math display">\[P(A|B) = \frac{P(B|A)· P(A)}{P(B)} \tag{3.8}\]</span></span></p>
<p>where A and B are events and <span class="math inline">\(P(B)\neq 0\)</span>.</p>
<div class="callout-caution callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Probabilities involved in Bayes’ theorem (Advanced)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The experiment B can be considered as the data collected in a given experiment. The event A is a model that is used to describe the data.</p>
<p>Accordingly, the probabilities involved in Bayes’ theorem can be interpreted as follows:</p>
<ol type="a">
<li><p><strong>P(B|A)</strong> is the probability, or <strong>likelihood</strong> L, of the data given the specified model. Notice how P(B|A) means that the model A is given, or known.</p></li>
<li><p><strong>P(A)</strong> is the probability of the model A, without any knowledge of the data.This term is interpreted as a <strong>prior probability</strong>, or the degree of belief that the model is true before the measurements are made.</p></li>
<li><p><strong>P(B)</strong> is the probability of collecting the dataset B.</p></li>
<li><p>Finally, <strong>P(A|B)</strong> is the <strong>posterior</strong> <strong>probability</strong> of the model after the data have been collected.The posterior probability is the ultimate goal of the analysis since it describes the probability of the model based on the collection of data.</p></li>
</ol>
<p>This interpretation of Bayes’ theorem is the foundation of Bayesian statistics, and it can be summarized as:</p>
<p><strong>Posterior probability ∝ Likelihood × Prior probability</strong></p>
<p>Bayes’ theorem provides a way to <strong>update</strong> the prior knowledge of model parameters given the measurements, leading to posterior estimates of parameters. One key feature of Bayesian statistics is that the calculation of probability is based on a <strong>prior probability</strong>, which may rely on a subjective interpretation of what is known about the experiment before any measurements are made. Therefore, great attention must be paid to the assignment of prior probabilities and the effect of priors on the final results of the analysis.</p>
</div>
</div>
</div>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example - Probability of developing lung cancer for smokers
</div>
</div>
<div class="callout-body-container callout-body">
<p>Suppose that the probability of having lung cancer is P(C) = 0.001 and that the probability of being a smoker is P(SM) = 0.25</p>
<p>Further, suppose we know that if a person has lung cancer, the probability of being a smoker increases to P(SM|C) = 0.4. We are, however, interested in the probability of developing lung cancer if a person is a smoker, P(C|SM).</p>
<p>From <a href="#eq-bayes">Equation&nbsp;<span>3.8</span></a>:</p>
<p><span class="math display">\[P(C|SM) = \frac{P(SM|C)· P(C)}{P(SM)} = \frac{0.4· 0.001}{0.25}= 0.0016\]</span> Therefore, the probability of lung cancer increases from 0.001 to 0.0016 for smokers. That is, the probability becomes 60% higher than the overall probability of lung cancer.</p>
</div>
</div>
<p>&nbsp;</p>
</section></section><section id="random-variables" class="level2" data-number="3.3"><h2 data-number="3.3" class="anchored" data-anchor-id="random-variables">
<span class="header-section-number">3.3</span> Random Variables</h2>
<p>Formally, a random variable X assigns a numerical value to each possible outcome of a random phenomenon. For instance, we can define X based on possible genotypes of a bi-allelic gene A as follows:</p>
<p><span class="math display">\[X={\begin{cases}0,&amp;for\ genotype\ AA\\1,&amp;for\ genotype\ Aa\\2,&amp;for\ genotype\ aa\end{cases}}\]</span></p>
<p>In this case, the random variable assigns 0 to the outcome AA, 1 to the outcome Aa, and 2 to the outcome aa.</p>
<p>The set of values that a random variable can assume is called its range. For the above example, the range of X is {0, 1, 2}.</p>
<p>After we define a random variable, we can find the probability for its possible value based on the underlying random phenomenon. This way, instead of talking about the probability for different outcomes and events, we can talk about <strong>the probability of different values for a random variable</strong>.</p>
<p>Assume that the individual probabilities for different genotypes are P(AA) = 0.49, P(Aa) = 0.42, and P(aa) = 0.09. Then, instead of saying P(AA) = 0.49, i.e., the genotype is AA with probability 0.49, we can say that P(X = 0) = 0.49, i.e., X is equal to 0 with probability of 0.49. Likewise, P(X = 1) = 0.42 and P(X = 2) = 0.09.</p>
<p>Note that the total probability for the random variable is still 1. In what follows, we write P(X) to denote the probability of a random variable X in general without specifying any value or range of values. <strong>The probability rules we discussed earlier also apply to random variables</strong>. Specifically, concepts such as independence and conditional probability are defined similarly for random variables as they are defined for random events. For example, when two random variables do not affect each other’s probabilities, we say that they are independent.</p>
<p>A random variable is also expected to have a theoretical distribution, e.g., Normal, Poisson, etc., according to the nature of the variable itself and the method of measurement.</p>
<p>Each distribution is entirely defined by several specific parameters. The parameter values determine the location and shape of the curve on the plot of distribution, and each unique combination of parameter values produces a unique distribution curve.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
What do we need to know for a random variable?
</div>
</div>
<div class="callout-body-container callout-body">
<p>To fully understand a random variable, we need to know:</p>
<ol type="1">
<li>
<strong>every possible value</strong>, or the interval of values of the random variable.</li>
<li>the <strong>probability</strong> corresponding to each possible value or value ranges (<strong>probability distribution</strong>).</li>
</ol>
</div>
</div>
<p>For the random variable X defined based on genotypes, the <strong>probability distribution</strong> can be simply specified as follows:</p>
<p><span class="math display">\[P(X=x)={\begin{cases}0.49,&amp;for\ x=0\\0.42,&amp;for\ x=1\\0.09,&amp;for\ x=2\end{cases}}\]</span> Here, x denotes a specific value (i.e., 0, 1, or 2) of the random variable. Probability distributions are specified differently for different types of random variables. In the following, we divide the random variables into two major groups: <strong>discrete</strong> and <strong>continuous</strong>. Then, we provide several examples for each group.</p>
</section><section id="probability-distributions-for-discrete-outcomes" class="level2" data-number="3.4"><h2 data-number="3.4" class="anchored" data-anchor-id="probability-distributions-for-discrete-outcomes">
<span class="header-section-number">3.4</span> Probability distributions for Discrete Outcomes</h2>
<p>For discrete random variables, the probability distribution is fully defined by the <strong>probability mass function</strong> (pmf). This is a function that specifies the probability of each possible value within range of random variable.</p>
<p>&nbsp;</p>
<section id="bernoulli-distribution" class="level3"><h3 class="anchored" data-anchor-id="bernoulli-distribution"><strong>Bernoulli distribution</strong></h3>
<p>Binary random variables are abundant in scientific studies. Bernoulli distribution applies to events that have one trial and two possible outcomes.</p>
<p>A <strong>Bernoulli event</strong> is one for which the probability the event occurs (success; X=1) is p and the probability the event does not occur (failure; X=0) is 1-p.&nbsp;As before, the probability for all possible values is one: P(X = 0) + P(X = 1) = 1.</p>
<p>A <strong>Bernoulli trial</strong> is an instantiation of a Bernoulli event. So long as the probability of success or failure remains the same from trial to trial (i.e., each trial is independent of the others), a sequence of Bernoulli trials is called a <strong>Bernoulli process</strong>.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
<strong>Definition-Bernoulli distribution</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<p>The binary random variable X with possible values 0 and 1 has a Bernoulli distribution with parameter p , where P(X = 1) = p and P(X = 0) = 1 − p . We denote this as X ∼ Bernoulli(p), where 0 ≤ p ≤ 1.</p>
<p>Here, p is the unknown parameter. If p were known, we could fully specify the probability mass function:</p>
<p><span class="math display">\[P(X=x)={\begin{cases}q=1-p,&amp;for\ x=0\\p,&amp;for\ x=1\end{cases}}\]</span></p>
<p>where <span class="math inline">\({0\leq p\leq 1}\)</span>.</p>
<p>The mean of a binary random variable, X, with Bernoulli(p) distribution is p.&nbsp;We show this as:</p>
<p><span id="eq-bernouli1"><span class="math display">\[μ = p \tag{3.9}\]</span></span></p>
<p>In this case, the mean can be interpreted as the proportion of the population who have the outcome of interest.</p>
<p>Furthermore, the variance of a random variable with Bernoulli(p) distribution is:</p>
<p><span id="eq-bernouli2"><span class="math display">\[ \sigma^2= pq=p(1-p)= μ(μ-1) \tag{3.10}\]</span></span></p>
<p><span id="eq-bernouli3"><span class="math display">\[ \sigma= \sqrt{p(1-p)}= \sqrt{μ(μ-1)} \tag{3.11}\]</span></span></p>
</div>
</div>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
<strong>Example-Bernoulli distribution: breast cancer</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<p>For example, let X be a random variable representing the five-year survival status of breast cancer patient, where X = 1 if the patient survived and X = 0 otherwise. Suppose that the probability of survival is p = 0.8: P(X = 1) = 0.8. Therefore, the probability of not surviving is P(X = 0) = 1 − p = 0.2. Then X has a Bernoulli distribution with parameter p = 0.8, and we denote this as</p>
<p><span class="math display">\[X ∼ Bernoulli(0.8)\]</span> The pmf for this distribution is:</p>
<p><span class="math display">\[P(X=x)={\begin{cases}0.2,&amp;for\ x=0\\0.8,&amp;for\ x=1\end{cases}}\]</span> Additionally, we can plot pmf for visualizing the distribution <a href="#fig-bern1">Figure&nbsp;<span>3.2</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-bern1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-bern1-1.png" class="img-fluid figure-img" style="width:80.0%"></p>
<p></p><figcaption class="figure-caption">Figure 3.2: Plot of the pmf for Bernoulli(0.8) distribution.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The height of each bar is the probability of the corresponding value on the horizontal axis. The height of the bar is 0.2 at X = 0 and 0.8 at X = 1. Since the probability for all possible values of the random variable is 1, the bar heights add up to 1.</p>
<p>In the above example, from <a href="#eq-bernouli1">Equation&nbsp;<span>3.9</span></a> we take μ = 0.8. Therefore, we expect 80% of patients survive.</p>
<p>From <a href="#eq-bernouli2">Equation&nbsp;<span>3.10</span></a> the variance of the random variable is <span class="math inline">\(σ^2 = 0.8 × 0.2 = 0.16\)</span>, and its standard deviation is <span class="math inline">\(σ = 0.4\)</span>. This reflects the extent of variability in survival status from one person to another. For this example, the amount of variation is rather small. Therefore, we expect to see many survivals (X = 1) with occasional death (X = 0). For comparison, suppose that the probability of survival for bladder cancer is θ = 0.6. Then, the variance becomes <span class="math inline">\(σ^2 = 0.6×(1−0.6) = 0.24\)</span>. This reflects a higher variability in the survival status for bladder cancer patients compared to that of breast cancer patients.</p>
</div>
</div>
<p>&nbsp;</p>
</section><section id="binomial-distribution" class="level3"><h3 class="anchored" data-anchor-id="binomial-distribution"><strong>Binomial distribution</strong></h3>
<p>The binomial distribution is an important theoretical distribution with wide applications in biomedicine. Many biological phenomena can be described using a binomial distribution.</p>
<p>The Bernoulli distribution represents the success or failure of a single Bernoulli trial. The Binomial Distribution represents the number of successes and failures in <span class="math inline">\(n\)</span> <strong>independent</strong> Bernoulli trials for some given value of n.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
<strong>Definition-Binomial distribution</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<p>The random variable X representing the <strong>number of times</strong> the outcome of interest occurs in <span class="math inline">\(n\)</span> Bernoulli trials has a <span class="math inline">\(Binomial(n, p)\)</span> distribution, where p is the probability of the outcome of interest (success). A binomial distribution is defined by the number of Bernoulli trials <span class="math inline">\(n\)</span> and the probability of the outcome of interest p for the underlying Bernoulli trials.</p>
<p><span id="eq-binom0"><span class="math display">\[ P(X=x) = {{n}\choose{x}} \cdot p^xq^{n-x} \tag{3.12}\]</span></span></p>
<p>where x = 0, 1, … , n, <span class="math inline">\({0\leq p\leq 1}\)</span>, q = 1 − p</p>
<p>If is a binomial random variable with parameters and n and p, then</p>
<p><span id="eq-binom1"><span class="math display">\[μ = np \tag{3.13}\]</span></span></p>
<p><span id="eq-binom2"><span class="math display">\[σ^2 = npq \tag{3.14}\]</span></span></p>
<p><span id="eq-binom3"><span class="math display">\[σ = \sqrt{npq} \tag{3.15}\]</span></span></p>
</div>
</div>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
<strong>Example-Binomial distribution: breast cancer</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Suppose that we plan to recruit a group of 50 patients with breast cancer and study their survival within five years from diagnosis. We represent the survival status for these patient by a set of Bernoulli random variables <span class="math inline">\(X_1, . . . , X_{50}\)</span>. (For each patient, the outcome is either 0 or 1). Assuming that all patients have the same survival probability, p = 0.8, and the survival status of one patient does not affect the probability of survival for another patient, <span class="math inline">\(X_1, . . . , X_{50}\)</span> form a set of 50 Bernoulli trials.</p>
<p>Now we can create a new random variable X representing the number of patients out of 50 who survive for five years. The number of survivals is the number of 1s in the set of Bernoulli trials. This is the same as the sum of Bernoulli trials, whose values are either 0 or 1:</p>
<p><span id="eq-X"><span class="math display">\[X=\sum_{i=1}^{50}X_{i} \tag{3.16}\]</span></span></p>
<p>where <span class="math inline">\(X_i = 1\)</span> if the ith patient survive and <span class="math inline">\(X_i = 0\)</span> otherwise.</p>
<p>Since X can be any integer number from 0 (no one survives) through 50 (everyone survives), its range is {0, 1, . . . , 50}. The range is a countable set. Therefore, the random variable X is discrete. The probability distribution of X is a binomial distribution, shown as:</p>
<p><span class="math display">\[X ∼ Binomial(50, 0.8)\]</span></p>
<p>The pmf of Binomial(50, 0.8) distribution specifies the probability of 0 through 50 survivals.</p>
<p>According to <a href="#eq-binom0">Equation&nbsp;<span>3.12</span></a> we have:</p>
<table class="table"><tbody>
<tr class="odd">
<td><strong>X</strong></td>
<td>0</td>
<td>1</td>
<td>…</td>
<td>34</td>
<td>35</td>
<td>36</td>
<td>…</td>
<td>40</td>
<td>…</td>
</tr>
<tr class="even">
<td><strong>P(X)</strong></td>
<td>0</td>
<td>0</td>
<td>…</td>
<td>0.02</td>
<td>0.03</td>
<td>0.05</td>
<td>…</td>
<td>0.14</td>
<td>…</td>
</tr>
</tbody></table>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-binom1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-binom1-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 3.3: Plot of the pmf for Binomial(50, 0.8) distribution.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>As before, the height of each bar is the probability of the corresponding value on the x-axis. For example, the probability of 40 survivals (out of 50) is P(X=40)=0.14. Also, since the probability for all possible values of the random variable is 1, the bar heights add up to 1. Note that for numbers below 30 and above 48, the probability is almost zero.</p>
<p>Now suppose that we are interested in the probability that either 34 or 35 or 36 patients survive. Since the underlying event include three possible outcomes, 34, 35, and 36, we obtain the probability by adding the individual probabilities for these outcomes:</p>
<p><span class="math display">\[P(33&lt;X ≤ 36) = P(X = 34)+ P(X = 35)+P(X = 36) = 0.02 + 0.03 + 0.05 = 0.1\]</span></p>
<p>For the breast cancer example and <a href="#eq-binom1">Equation&nbsp;<span>3.13</span></a>, the mean of the random variable is 50×0.8 = 40. If we recruit 50 patients, we expect 40 people survive over five years. Of course, the actual number of survivals can change from one group to another (e.g., if we take another group of 50 patients). According to <a href="#eq-binom2">Equation&nbsp;<span>3.14</span></a>, the variance of X in the above example is 50 × 0.8 × 0.2 = 8, which shows the extent of the variation of the random variable around its mean.</p>
</div>
</div>
</section><section id="poisson-distribution" class="level3"><h3 class="anchored" data-anchor-id="poisson-distribution"><strong>Poisson distribution</strong></h3>
<p>So far, we have discussed the Bernoulli distribution for binary variables, and the binomial distribution for the number of times the outcome of interest (one of the two possible categories of the binary variable) occur within a set of n Bernoulli trials.</p>
<p>While a random variable with a Binomial distribution is a count variable (e.g., number of people survived), its range is restricted to include integers from 0 through n only. For example, the number of survivals in a group of n = 50 cancer patients cannot exceed 50.</p>
<p>Now, suppose that we are investigating the <strong>number of physician visits for each person in one year</strong>. Although very large numbers such as 100 are quite unlikely, there is no theoretical and prespecified upper limit to this random variable. Theoretically, its range is the set of all nonnegative integers.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
<strong>Definition-Poisson distribution</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<p>Random variables representing counts within temporal and/or spacial limits but without prespecified upper limits are often assumed to have Poisson distributions. The range of these variables is the set of all non negative integers (i.e., the lower limit is zero, but there is no upper limit). A Poisson distribution is specified by a parameter λ, which is interpreted as the <strong>rate of occurrence within a time period or space limit</strong>. We show this as X ∼ Poisson(λ), where λ is a positive real number (λ&gt;0).</p>
<p><span id="eq-poisson1"><span class="math display">\[ P(X=x)={\frac {\lambda ^{x}e^{-\lambda }}{x!}}  \tag{3.17}\]</span></span></p>
<p>where x = 0, 1, … +∞, λ &gt; 0.</p>
<p>The mean and variance of a random variable with Poisson(λ) distribution are the same and equal to λ. That is, μ = λ and <span class="math inline">\(σ^2 = λ\)</span>.</p>
</div>
</div>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
<strong>Example-Poisson distribution: physician visits</strong>
</div>
</div>
<div class="callout-body-container callout-body">
<p>As an example, assume that the rate of physician visits per year is 2.5:</p>
<p><span class="math display">\[X ∼ Poisson(2.5)\]</span> Therefore, the population mean and variance of this variable is 2.5.</p>
<p>According to <a href="#eq-poisson1">Equation&nbsp;<span>3.17</span></a> the resulting probability table is:</p>
<table class="table"><tbody>
<tr class="odd">
<td><strong>X</strong></td>
<td>0</td>
<td>1</td>
<td>2</td>
<td>3</td>
<td>5</td>
<td>6</td>
</tr>
<tr class="even">
<td><strong>P(X)</strong></td>
<td>0.08</td>
<td>0.21</td>
<td>0.26</td>
<td>0.21</td>
<td>0.07</td>
<td>0.03</td>
</tr>
</tbody></table>
<p>The resulting plot of the pmf shows the probability of each possible value, which is any integer from 0 to infinity <a href="#fig-poisson1">Figure&nbsp;<span>3.4</span></a>. In this case, the probability of values above 8 becomes almost 0.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-poisson1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-poisson1-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 3.4: Plot of the pmf for Poisson(2.5) distribution.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>For this example, the probability that a person does not visit her/his physician within a year is P(X = 0) = 0.08, while the probability of one visit per year increases to P(X = 1) = 0.21.</p>
<p>Now suppose that we want to know the probability of up to three visits per year: P(X ≤ 3). This is the probability that a person visit her/his physician 0, or 1, or 2, or 3 times within one year. As before, we add the individual probabilities for the corresponding outcomes: P(X ≤ 3) = 0.08 + 0.21 + 0.26 + 0.21 = 0.76.</p>
<p>The population mean and variance of this variable is 2.5 visits per year.</p>
</div>
</div>
</section></section><section id="probability-distributions-for-continuous-outcomes" class="level2" data-number="3.5"><h2 data-number="3.5" class="anchored" data-anchor-id="probability-distributions-for-continuous-outcomes">
<span class="header-section-number">3.5</span> Probability distributions for Continuous Outcomes</h2>
<p>For discrete random variables, the pmf provides the probability of each possible value. For continuous random variables, the number of possible values is uncountable, and the probability of any specific value is zero.</p>
<p>Therefore, instead of talking about the probability of any specific value x for continuous random variable X, we talk about the probability that the value of the random variable is within a specific interval from x1 to x2; we show this probability as P(x1 ≤ X ≤ x2).</p>
<p><span id="eq-continuous1"><span class="math display">\[ P(x_1\leq X \leq x_2)=\int_{x_1}^{x_2}f(x)dx  \tag{3.18}\]</span></span></p>
<p>where f(x) is the probability density functions (pdf) of X .</p>
<p>Clearly, in <a href="#eq-continuous1">Equation&nbsp;<span>3.18</span></a>, the probability of a certain point value in X is zero, and the area under the probability density curve of the interval (−∞, +∞) should be 1.</p>
<p>&nbsp;</p>
<section id="normal-distribution" class="level3"><h3 class="anchored" data-anchor-id="normal-distribution"><strong>Normal Distribution</strong></h3>
<p>There are several important probability distributions in statistics. However, the normal distribution might be the most important. First, Galileo informally described a normal distribution in 1632 when discussing the random errors from observations of celestial phenomena. However, Galileo existed before the time of differential equations and derivatives. We owe its formalization to Carl Friedrich Gauss, which is why the normal distribution is often called a Gaussian distribution. A very familiar example is the height for adult people that approximates a normal distribution very well.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Definition and Properties of Normal Distribution
</div>
</div>
<div class="callout-body-container callout-body">
<p>A normal distribution is the familiar “bell curve” and it’s a way of formalizing a distribution where observations cluster around some central tendency. Observations farther from the central tendency occur less frequently.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-dnormal" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-dnormal-1.png" class="img-fluid figure-img" style="width:100.0%"></p>
<p></p><figcaption class="figure-caption">Figure 3.5: The Normal probability distribution (often called Gaussian or bell-shaped distribution).</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Gauss’ normal distribution, technically a density function, is a distribution defined by two parameters, mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. The mean, <span class="math inline">\(\mu\)</span>, represents the population mean and is a “location parameter”, which defines the central tendency. The variance, <span class="math inline">\(\sigma^2\)</span> is the “scale parameter”, which defines the width of the distribution and how short the distribution is. It’s formally given as <a href="#eq-gauss">Equation&nbsp;<span>3.19</span></a>:</p>
<p><span id="eq-gauss"><span class="math display">\[ f(x)={\frac {1}{\sigma {\sqrt {2\pi }}}}e^{-{\frac {1}{2}}\left({\frac {x-\mu }{\sigma }}\right)^{2}}  \tag{3.19}\]</span></span></p>
<p>Populations with small values of the standard deviation, <span class="math inline">\(\sigma\)</span>, have a distribution concentrated close to the centre, <span class="math inline">\(\mu\)</span>; those with large standard deviation, <span class="math inline">\(\sigma\)</span>, have a distribution widely spread along the measurement axis <a href="#fig-compare_normal">Figure&nbsp;<span>3.6</span></a>.</p>
<div id="fig-compare_normal" class="cell quarto-layout-panel">
<figure class="figure"><div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-compare_normal-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-compare_normal-1.png" class="img-fluid figure-img" data-ref-parent="fig-compare_normal" width="672"></p>
<p></p><figcaption class="figure-caption">(a) Effect of changing mean.</figcaption><p></p>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-compare_normal-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-compare_normal-2.png" class="img-fluid figure-img" data-ref-parent="fig-compare_normal" width="672"></p>
<p></p><figcaption class="figure-caption">(b) Effect of changing standard deviation.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Figure 3.6: Probability distribution functions of the Normal distributions with different means and standard deviations.</figcaption><p></p>
</figure>
</div>
<p>The Normal distribution has the properties summarized as follows:</p>
<ul>
<li><p>Bell shaped and symmetrical around the mean. Shape statistics, skewness and excess kurtosis are zero.</p></li>
<li><p>The peak of the curve lies above the mean.</p></li>
<li><p>Any position along the horizontal axis (x-axis) can be expressed as a number of standard deviations from the mean.</p></li>
<li><p>All three measures of central tendency mean, the median, and the mode will be the same.</p></li>
<li><p>Much of the area (68%) of the distribution is between -1 <span class="math inline">\(\sigma\)</span> below the mean and +1 <span class="math inline">\(\sigma\)</span> above the mean, the large majority (95%) between -1.96 <span class="math inline">\(\sigma\)</span> below the mean and +1.96 <span class="math inline">\(\sigma\)</span> above the mean (often used as a reference range), and almost all (99%) between -2.58 <span class="math inline">\(\sigma\)</span> below the mean and +2.58 <span class="math inline">\(\sigma\)</span> above the mean. The total area under the curve equals to 1 (or 100%).</p></li>
</ul>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-normal_auc" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-normal_auc-1.png" class="img-fluid figure-img" width="1200"></p>
<p></p><figcaption class="figure-caption">Figure 3.7: The area underneath a Normal Distribution</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</div>
<p>&nbsp;</p>
<div class="callout-note callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Example-Normal distribution: systolic blood pressure
</div>
</div>
<div class="callout-body-container callout-body">
<p>Suppose we know that the population mean and standard deviation for systolic blood pressure (sbp) are μ = 125 mmHg and σ = 15 mmHg, respectively.</p>
<ol type="a">
<li>About what percentage of population has sbp in the range μ±σ ?</li>
</ol>
<p>The X random variable of sbp follows the normal distribution:</p>
<p><span class="math display">\[ X ∼ N(125, 15^2)\]</span></p>
<p>Thus, the percentage of the distribution between -1 <span class="math inline">\(\sigma\)</span> below the mean and +1 <span class="math inline">\(\sigma\)</span> above the mean is:</p>
<p><span class="math display">\[ P(125 −15≤X≤ 125+15) = P(110≤X≤ 140) = 0.68\ or\ 68\% \]</span></p>
<ol start="2" type="a">
<li>Calculate a 95% reference range for the sbp:</li>
</ol>
<p><span class="math display">\[ (125 - 1.96\times 15,\ 125 + 1.96\times 15) = (95.6, 154.4) \]</span></p>
</div>
</div>
<p>&nbsp;</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Statistical moments (or shape statistics) and normality
</div>
</div>
<div class="callout-body-container callout-body">
<p>There are two shape statistics that can indicate deviation from normality: <strong>skew</strong> and <strong>kurtosis</strong>.</p>
<p><strong>Skewness</strong></p>
<p>Skewness is usually described as a measure of a dataset’s symmetry – or lack of symmetry.</p>
<p>Skewness values that are <strong>negative</strong> indicate a tail to the <strong>left</strong> (<a href="#fig-skew2">Figure&nbsp;<span>3.8</span></a> a), <strong>zero</strong> value indicate a <strong>symmetric</strong> distribution (<a href="#fig-skew2">Figure&nbsp;<span>3.8</span></a> b), while values that are <strong>positive</strong> indicate a tail to the <strong>right</strong> (<a href="#fig-skew2">Figure&nbsp;<span>3.8</span></a> c).</p>
<p>Skewness values between −1 and +1 indicate an approximate bell-shaped curve. Values from −1 to −3 or from +1 to +3 indicate that the distribution is tending away from a bell shape with &gt;1 indicating moderate skewness and &gt;2 indicating severe skewness. Any values above +3 or below−3 are a good indication that the variable is not normally distributed.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-skew2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/skew2.PNG" class="img-fluid figure-img" style="width:105.0%"></p>
<p></p><figcaption class="figure-caption">Figure 3.8: A distribution can be (a) skewed to the left, (b) symmetric, or (c) skewed to the right.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>&nbsp;</p>
<p><strong>Kurtosis</strong></p>
<p>The other way that distributions can deviate from normality is <strong>kurtosis</strong>. The kurtosis parameter is a measure of the combined weight of the tails relative to the rest of the distribution. Kurtosis is associated indirect with the peak of the distribution (if the peak of the distribution is too high or too low).</p>
<p>Distributions with <strong>negative</strong> excess kurtosis are called <strong><em>platykurtic</em></strong> (<a href="#fig-kurtosis">Figure&nbsp;<span>3.9</span></a> a). If the measure of excess kurtosis is <strong>0</strong> the distribution is <strong>mesokurtic</strong> (<a href="#fig-kurtosis">Figure&nbsp;<span>3.9</span></a> b). Finally, distributions with <strong>positive</strong> excess kurtosis are called <strong><em>leptokurtic</em></strong> (<a href="#fig-kurtosis">Figure&nbsp;<span>3.9</span></a> c).</p>
<p>A kurtosis value between −1 and +1 indicates normality and a value between −1 and −3 or between +1 and +3 indicates a tendency away from normality. Values below −3 or above +3 strongly indicate non-normality.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-kurtosis" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="images/kurtosis.PNG" class="img-fluid figure-img" style="width:105.0%"></p>
<p></p><figcaption class="figure-caption">Figure 3.9: A distribution can be (a) platykurtic, (b) mesokurtic, or (c) leptokurtic.</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</div>
<p>&nbsp;</p>
<p>The normal distribution provides an adequate model for the relative frequency distributions of data (empirical distributions) collected from many different biomedical areas, such as adult height, weight, vital capacity, and red blood cell count. Moreover, many other distributions that are not normal themselves can be made approximately normal by transforming the data into a different scale.</p>
<p>If the shape of empirical distributions of random variables approximates the Gaussian distribution then the variables are considered to be distributed normally.</p>
<div class="callout-tip callout callout-style-default no-icon callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon no-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Properties of an approximately bell-shaped empirical distribution
</div>
</div>
<div class="callout-body-container callout-body">
<p>In an approximately <strong>bell-shaped</strong> distribution:</p>
<ul>
<li><p>the mean, the median and the mode have very close values</p></li>
<li><p>the histogram is symmetric about the mean</p></li>
<li><p>“nearly all” values (99.7%) are within -3 and +3 standard deviations of the mean</p></li>
<li><p>the measure of skewness takes values close to zero (symmetric distribution) (<a href="#fig-skew2">Figure&nbsp;<span>3.8</span></a> b). Particularly, values between −1 and +1 indicate an approximately bell-shaped curve.</p></li>
<li><p>the measure of excess kurtosis is close to 0 (mesokurtic) (<a href="#fig-kurtosis">Figure&nbsp;<span>3.9</span></a> b). A kurtosis value between −1 and +1 indicates normality.</p></li>
</ul>
</div>
</div>
<p>&nbsp;</p>
<p>&nbsp;</p>
</section><section id="standard-normal-distribution" class="level3"><h3 class="anchored" data-anchor-id="standard-normal-distribution"><strong>Standard Normal distribution</strong></h3>
<p>If the random variable X has a normal distribution with <span class="math inline">\(\mu\)</span> and standard deviation <span class="math inline">\(\sigma\)</span>, then the standardized Normal deviate is:</p>
<p><span id="eq-z"><span class="math display">\[ z= \frac{x-\mu}{\sigma}  \tag{3.20}\]</span></span></p>
<p>The z is a random variable that has a Standard Normal distribution, also called a z-distribution, i.e.&nbsp;a special normal distribution where <span class="math inline">\(\mu=0\)</span> and <span class="math inline">\(\sigma^2=1\)</span>. In this case, <a href="#eq-gauss">Equation&nbsp;<span>3.19</span></a> is transformed as follows:</p>
<p><span id="eq-zd"><span class="math display">\[ f(z)={\frac {1}{{\sqrt {2\pi }}}}e^{-{\frac {1}{2}}z^2}  \tag{3.21}\]</span></span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-simple_normal" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-simple_normal-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">Figure 3.10: A simple normal density function.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>The standard normal distribution is centered at zero and the probability that z is between 1 on either side of 0 is effectively 0.68. The ease of this interpretation is why researchers like to standardize their variables so that the mean is 0 and the standard deviation is 1.</p>
<p>&nbsp;</p>
<div class="callout-caution callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-23-contents" aria-controls="callout-23" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Understanding the Standard Normal distribution
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-23" class="callout-23-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>We can break down individual components of a z-distribution (<a href="#eq-z">Equation&nbsp;<span>3.20</span></a>) and explain them until they seem more accessible.</p>
<p><strong>First</strong>, we know from algebra that the formula <span class="math inline">\(\ {\frac {1}{2}}z^{2}\)</span> is a basic parabola (notice the square term). Adding a minus sign just flips the basic parabola <span class="math inline">\(\ {\frac {1}{2}}z^{2}\)</span> downward and we take a negative parabola <span class="math inline">\(\ -{\frac {1}{2}}z^{2}\)</span>.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-basic_parabola" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-basic_parabola-1.png" class="img-fluid figure-img" width="768"></p>
<p></p><figcaption class="figure-caption">Figure 3.11: (a) A basic parabola and (b) a negative parabola.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p><strong>Second</strong>, exponentiating the negative parabola (<span class="math inline">\(\  e^{-{\frac {1}{2}}z^{2}}\)</span>) makes it asymptote to 0.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-neg_parabola" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-neg_parabola-1.png" class="img-fluid figure-img" width="576"></p>
<p></p><figcaption class="figure-caption">Figure 3.12: An exponentiated negative parabola.</figcaption><p></p>
</figure>
</div>
</div>
</div>
<p>Notice the tails in the <a href="#fig-neg_parabola">Figure&nbsp;<span>3.12</span></a> are asymptote to 0. “Asymptote” is a fancier way of saying the tails approximate 0 but never touch or surpass 0. One way of thinking about this as we build toward its inferential implications is that deviations farther from the central tendency are increasingly “unlikely”.</p>
<p><strong>Third</strong>, and with the above point in mind, it should be clear that <span class="math inline">\(\ {\frac {1}{{\sqrt {2\pi }}}}\)</span> will scale the height of the distribution. Observe that the height of the exponentiated parabola is at 1. That gets multiplied by <span class="math inline">\(\ {\frac {1}{\sqrt {2\pi }}}\)</span> to equal about 0.398.</p>
<p><strong>Fourth</strong>, the z-distribution is perfectly symmetrical around the zero. A given value of z will be as far from zero as -z.</p>
<p><strong>Fifth</strong>, if we want to find the area E between <span class="math inline">\(z_1\)</span> = 1 and <span class="math inline">\(z_2\)</span> = 2, we must integrate the <a href="#eq-zd">Equation&nbsp;<span>3.21</span></a> as following:</p>
<p><span id="eq-integral"><span class="math display">\[ E=P(z_1\leq Z\leq z_2)={\frac {1}{{\sqrt {2\pi }}}}\int_{z_1}^{z_2}e^{-{\frac {1}{2}}z^2}dz  \tag{3.22}\]</span></span></p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-standard_normal" class="quarto-figure quarto-figure-center anchored">
<figure class="figure"><p><img src="distributions_files/figure-html/fig-standard_normal-1.png" class="img-fluid figure-img" width="768"></p>
<p></p><figcaption class="figure-caption">Figure 3.13: Standard normal distribution with a shaded region</figcaption><p></p>
</figure>
</div>
</div>
</div>
</div>
</div>
</div>
<p>&nbsp;</p>
<section id="t-distribution" class="level4"><h4 class="anchored" data-anchor-id="t-distribution"><strong>t-distribution</strong></h4>
</section><section id="chi-squared-distribution" class="level4"><h4 class="anchored" data-anchor-id="chi-squared-distribution"><strong>Chi-squared distribution</strong></h4>
</section><section id="f-distribution" class="level4"><h4 class="anchored" data-anchor-id="f-distribution"><strong>F-distribution</strong></h4>


</section></section></section></main><!-- /main --><script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    setTimeout(function() {
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      let href = ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const cites = ref.parentNode.getAttribute('data-cites').split(' ');
    tippyHover(ref, function() {
      var popup = window.document.createElement('div');
      cites.forEach(function(cite) {
        var citeDiv = window.document.createElement('div');
        citeDiv.classList.add('hanging-indent');
        citeDiv.classList.add('csl-entry');
        var biblioDiv = window.document.getElementById('ref-' + cite);
        if (biblioDiv) {
          citeDiv.innerHTML = biblioDiv.innerHTML;
        }
        popup.appendChild(citeDiv);
      });
      return popup.innerHTML;
    });
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
      }
    }
});
</script><nav class="page-navigation"><div class="nav-page nav-page-previous">
      <a href="./descriptive.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Descriptive statistics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./estimation.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Estimation and Confidence Interval</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer"><div class="nav-footer">
    <div class="nav-footer-left">Copyright 2022, Konstantinos I. Bougioukas</div>   
  </div>
</footer>


</body></html>